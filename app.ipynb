{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import nltk\n",
    "import io\n",
    "from textblob import Word\n",
    "import re\n",
    "import sys, os, csv\n",
    "import string\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('C:\\\\Users\\\\Vishnu Vardhan\\\\Desktop\\\\capstone project file\\\\cleaned_data\\\\training.csv', sep=',')\n",
    "print(\"Dataset shape:\",data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "count = data_train.iloc[:,1].value_counts()\n",
    "fig = plt.figure(figsize=(9,7))  # Rename plt to fig\n",
    "sns.barplot(x = count.index, y = count.values, alpha=0.8, palette=\"plasma\")\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Emotions', fontsize=12)\n",
    "\n",
    "#sadness (0)\n",
    "#joy (1)\n",
    "#love (2)\n",
    "#anger (3)\n",
    "#fear (4)\n",
    "#neutral (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.iloc[:,0][:14399]\n",
    "#[:47583]\n",
    "y_train = data_train.iloc[:,-1][:14399]\n",
    "#[:47583]\n",
    "X_val = data_train.iloc[:,0][14400:]\n",
    "#[47584:]\n",
    "y_val = data_train.iloc[:,-1][14400:]\n",
    "#[47584:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Count Vectors Parameters\n",
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(data_train.iloc[:,0].astype('U'))\n",
    "X_train_count =  count_vect.transform(X_train.astype('U'))\n",
    "X_val_count =  count_vect.transform(X_val.astype('U'))\n",
    "print(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = count_vect.fit_transform(data_train.iloc[:,0].astype('U'))\n",
    "print(bow.shape)\n",
    "word_freq = dict(zip(count_vect.get_feature_names(), np.asarray(bow.sum(axis=0)).ravel()))\n",
    "word_counter = collections.Counter(word_freq)\n",
    "word_counter_df = pd.DataFrame(word_counter.most_common(30), columns = ['word', 'freq'])\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "sns.barplot(x=\"word\", y=\"freq\", data= word_counter_df, ax=ax, palette=\"plasma\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg1 = LogisticRegression(C=1, max_iter=500)\n",
    "logreg1.fit(X_train_count, y_train)\n",
    "y_pred = logreg1.predict(X_val_count)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "conf_matrix_lr = confusion_matrix(y_val, y_pred)\n",
    "class_report = classification_report(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion matrix:\\n\", conf_matrix_lr)\n",
    "print(\"Classification report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from flask import Flask,request, jsonify,render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, redirect, url_for, render_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(logreg1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app = Flask(__name__, static_url_path='/static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('home.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@app.route('/result')\n",
    "##   return render_template('result.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/result', methods=['POST'])\n",
    "def results():\n",
    "    return render_template('result.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def prediction_emotion(tweet):\n",
    "   # tweet_count = count_vect.transform(tweet)\n",
    "   # tweet_pred = logreg1.predict(tweet_count)\n",
    "    # convert predictions to emotion labels\n",
    "    #emotion_labels = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'neutral'}\n",
    "    #predicted_emotion = [emotion_labels[pred] for pred in tweet_pred]\n",
    "    #return predicted_emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def prediction_emotion(text):\n",
    "    #count_vect = CountVectorizer()\n",
    "    #tweets = [text]\n",
    "    #tweet_count = count_vect.fit_transform(tweets)\n",
    "   # tweet_pred = model.predict(tweet_count)\n",
    "    #label_dict = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear',5: 'neutral'}\n",
    "    #predicted_emotion= label_dict[np.argmax(tweet_pred)]\n",
    "    #return predicted_emotion*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/prediction', methods=['POST'])\n",
    "def prediction():\n",
    "    return render_template('prediction.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict', methods=['GET','POST'])\n",
    "def predict():\n",
    "    text = request.form.get('text_1')\n",
    "    tweet_count = count_vect.transform([text])\n",
    "    tweet_pred = logreg1.predict(tweet_count)\n",
    "    # convert predictions to emotion labels\n",
    "    emotion_labels = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'neutral'}\n",
    "    predicted_emotion = emotion_labels[tweet_pred[0]]\n",
    "    return render_template('prediction.html', predicted_emotion=predicted_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
